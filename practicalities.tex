
\section{Install the Accelerator}

\subsection{Using the \texttt{pip} command}
The easiest way to install the Accelerator is by fetching it from the
PyPi repository
\begin{shell}
pip install accelerator
\end{shell}
Some prefer to install to a virtual environment and do something in
line with the following
\begin{shell}
python3 -m venv accvenv
source accvenv/bin/activate
pip install accelerator
\end{shell}
This will install the Accelerator to the \texttt{accvenv} virtual
environment.  Now, use for example the following command
\begin{shell}
ax --help
\end{shell}
to check that the installation worked.  The next step is to set up a
project.



\section{Set up a New Project}
In order to run, the Accelerator needs to have these things in place
\begin{itemize}
\item[] at least one \textsl{workdir} to store data in,
\item[] most likely a new \textsl{method package} directory to store new code in, and
\item[] a \textsl{configuration file} to set things up.
\end{itemize}
This is all taken care of by the \texttt{init} command.

\section{Daemon Configuration File}
\label{sec:configfile}

The configuration file specifies which method packages and workdirs
that are available for a project.  A template configuration file can
be generated using the \texttt{init} command as described on
page~\ref{init_command}.  Below is an example of a configuration file.
%\begin{leftbar}
\begin{snugshade}
\begin{verbatim}
# The configuration is a collection of key value pairs.
#
# Values are specified as
# key: value
# or for several values
# key:
#       value 1
#       value 2
#       ...
# (any leading whitespace is ok)
#
# Use ${VAR} or ${VAR=DEFAULT} to use environment variables.

slices: 23
workdirs:
        test /zbd/workdirs/test
        import ${HOME}/workdirs/import

# Target workdir defaults to the first workdir, but you can override it.
# target workdir: dev
# (this is where jobs without a workdir override are built)

method packages:
        dev
        accelerator.standard_methods
#       accelerator.test_methods   

urd: http://localhost:9000

result directory: ${HOME}/accelerator/results
source directory: /zbd/data/backblaze
logfile: ${HOME}/accelerator/daemon.log

# If you want to run methods on different python interpreters you can
# specify names for other interpreters here, and put that name after
# the method in methods.conf.
# You automatically get four names for the interpreter that started
# the daemon: DEFAULT, 3, 3.7 and 3.7.3 (adjusted to the actual
# version used). You can override these here, except DEFAULT.
# interpreters:
#       2.7 /path/to/python2.7
#       test /path/to/beta/python  
\end{verbatim}
\end{snugshade}%
%\end{leftbar}%

The configuration file above specifies 23 slices and two workdirs,
called \texttt{test} and \texttt{import}.  The \texttt{test} workdir
is specified using an absolute path, while the \texttt{import} workdir
is specified relative to the user's home directory using the shell
environment variable \texttt{\$HOME}.

The workdir that is specified first is the \textsl{target workdir},
where jobs are written to by default.  All other specified workdirs
will by default only be used for reading.  Any of the workdirs
specified could be written to, though, using the
\texttt{set\_workdir=} option to the \texttt{build} command, as
described on page~\ref{set_workdir}.

Methods packages available for use are the \texttt{standard\_methods} bundled
with the Accelerator, and methods defined in the
directory \texttt{dev} (if defined in \texttt{dev/methods.conf}).

\starttabletwo

\RPtwo \texttt{slices} & Number of slices used for the project.\\[1ex]

\RPtwo \texttt{workdirs} & A list of paths to workdir directories.  At
least one workdir needs to be defined.  All workdirs that are used
together must have the same number of slices.  It is possible to use
shell environment variables such as \texttt{\$\{HOME\}} when
specifying workdirs.

Unless overridden by the \texttt{target workdir}, the first workdir in
the list will be the default \textsl{target workdir} that is used for
all writing.  Other specified workdirs will only be read from, unless
overrided by the \texttt{build} call as described on
page~\ref{set_workdir}.\\[1ex]

\RPtwo \texttt{target workdir} & Name of the \textsl{target workdir}.
If specified this overrides the first item in the \texttt{workdirs}
list.\\[1ex]

\RPtwo \texttt{method packages} & A list of directories containing
methods.  These will be the only directories where the Accelerator can
``see'' methods.  \texttt{standard\_methods} is bundled with the
Accelerator and is commonly used.\\[1ex]

\RPtwo \texttt{urd} & If present, an URL to the Urd server.\\[1ex]

\RPtwo \texttt{result directory} & A common path that is available to
all jobs.  It has been used sparsely by the Accelerator team since it
voids the possibility to see where a file comes from.  Nevertheless,
in some projects it is valuable to have a common place where methods
store results, see section~\ref{sec:RESULT_DIR}.  A way to keep
traceability is to store the file in the job directory as usual, and
then create a soft link to it in \texttt{result\_directory}.\\[1ex]

\RPtwo \texttt{source directory} & Default root path for
\texttt{csvimport}.  This is to avoid rebuilds of imports if source
files are moved to another directory.  (This typically happens when
setting up a similar system on another physical machine.)  See
section~\ref{sec:SOURCE_DIR} on how to get access to
\texttt{source\_directory} from any method.\\[1ex]

\RPtwo \texttt{logfile} & Location of the Accelerator's log.\\[1ex]

\RPtwo \texttt{interpreters} & Name and path to python executables.
These are used in \texttt{methods.conf} to specify specific Python
versions (or virtual environments) for individual methods.  If
unspecified, methods will be executed using the same binary that runs
the Accelerator's daemon process.\\[1ex]

\stoptabletwo

It is possible to assign values in the configuration file using shell
environment variables.  In the example above, workdirs are specified
relative to \texttt{\$\{HOME\}}, for example.  In general, the
assignment is \texttt{\$\{VAR=DEFAULT\}}.



\clearpage

\section{Setting up Urd}
\label{sec:urd_setup}

\subsubsection{The Urd Source Files}

Urd is included in the \texttt{accelerator} repository, in the
subdirectory \texttt{accelerator/urd}.


\subsubsection{Dependencies}
Urd requires the \texttt{bottle} library to run.  It is bundled with
Debian-like systems, and can be installed by
\begin{shell}
sudo apt-get install python-bottle
\end{shell}
It can also be downloaded from the project's home page
\begin{verbatim}
https://bottlepy.org/docs/dev/
\end{verbatim}
as a single python file, \texttt{bottle.py}.  This file should be put
in the \texttt{accelerator/urd} directory.



\subsubsection{Creating a Database}
A new database is created by making a new directory and adding
a \texttt{passwd} file to it.  Urd takes care of the rest.  In
practice,
\begin{shell}
mkdir database_root
vi database_root/passwd
\end{shell}
where \texttt{vi} is just an editor picked by random.


\subsubsection{Starting Urd}
Urd is running as a daemon.  It is started like this (make sure
to \texttt{cd} into the \texttt{accelerator/urd}-directory.
\begin{shell}
./urd.py --path=<database_root> --port=<port>
\end{shell}
Where \texttt{<database\_root>} is a path to an Urd database,
and \texttt{<port>} is a port number, for example \texttt{6502}.

\subsection{The Urd Database}
The Urd database has the following structure
\begin{verbatim}
database_root/
    passwd
    database/
        user1/
            list1
            list2
        user2/
            list3
\end{verbatim}

\subsubsection{The \texttt{passwd} file}
The \texttt{passwd} file stores write access authentication.  The file
format is straightforward, each line is a user--password pair as follows
\begin{verbatim}
user:password
\end{verbatim}
For example, if the file contains the following line
\begin{verbatim}
ab:secret
\end{verbatim}
A build script issued like this
\begin{shell}
URD_AUTH=ab:secret ax run test
\end{shell}
will have write access to all lists belonging to the user \texttt{ab},
such as for example the \texttt{ab/test} and \texttt{ab/import} lists.
But it can not write to lists belonging to other users, such
as \texttt{cd/import}.  It can read all lists, though.





\section{Workdirs}

Jobs are stored in \textsl{workdirs}.  The Accelerator must have one
target workdir, and may optionally have several source workdirs.
Target and source workdirs are specified in the daemon configuration
file.

By default, the only workdir that is written to is the target workdir,
while the source workdirs are for reading.  It is possible to override
this, however, by setting the \mintinline{python}|workdir=| option in
the \texttt{urd.build()} call, see section~\ref{sec:urd_build}.

Jobdirs are stored in the workdir by the daemon, and jobdirs will
inherit the workdir name and add a suffix that is an incremental job
counter.  Here is an example of a workdir named \texttt{test}, that
contains three jobdirs.
\begin{shell}
test/
    test-slices.conf
    test-0/
    test-1/
    test-2/
    test-LATEST -> test-2
\end{shell}
The link \texttt{<workdir>-LATEST} is always pointing to the last
jobdir created.  This is useful for example when iteratively testing a
method and accessing its data for example for plotting purposes.  Each
new build of the (modified) method will create a new job and jobid,
but the link will always point to the most recent version.


\subsection{Creating a Workdir}
Any empty directory can be a workdir.  To create a new workdir, create
the directory and add it in the configuration file either as source or
target workdir.  Stop and restart the \texttt{daemon}.  Upon startup,
any uninitialised source or target workdir in the configuration file
will be initialised.

The initiation process creates a file named
\texttt{<workdir>-slices.conf} that indicates that the directory is
now a workdir.  The file itself will contain the number of slices that
is used for the workdir.







\section{Progress Indication:  \texttt{C-t}}

During job building, it is possible to press \texttt{C-t},
i.e.\ \texttt{Ctrl} + \texttt{t} simultaneously, to get status
information.  The status will cover the processing state, if it is in
\prepare, \analysis, or \synthesis, reading or writing files, etc.

If the \analysis function is executing, \texttt{C-t} will list all
analysis processes that are active at the moment.  If iterating over a
dataset, the status message will include which dataset (perhaps in a
chain) that is currently being iterated.

Note that \texttt{C-t} could be pressed either in the \texttt{daemon}
or \texttt{run} shells.



\section{Typical Installation}

See the Accelerator Installation Manual for current installation
guidelines.

Traditionally, the Accelerator is installed as a \texttt{git
submodule} as part of the project it is used in.  This makes it
straightforward to update the Accelerator and project code
independently, while linking a specific version of the Accelerator to
the project.  Thus, the project will always use a specific Accelerator
commit, making the project independent of changes to the Accelerator.

Here is a typical setup
\begin{shell}
project/
    accelerator/
    dev/
    conf/
\end{shell}
Methods are stored in the \texttt{dev} directory, and Accelerator
configuration files in \texttt{conf}.  All files are version
controlled using \texttt{git}, and the \texttt{accelerator} directory
is a \texttt{git submodule}, which means that the project repository
is storing the repository location \textsl{and} the commit of the
Accelerator.





\section{Working with Relative Paths}

In some situations, like importing data from files, it is convenient
to store the absolute path of the files as a configuration parameter
and then work only with relative paths in the source code.  This has
two advantages.
\begin{itemize}
\item[] First, it makes it possible to move source files around without
forcing a re-build of the import jobs, and
\item[] second, absolute paths will not be stored in the source code.
\end{itemize}
In order to make use of relative paths, store the ``system dependent''
left part of the path in the Accelerator's configuration file.  There
are two variables in the configuration file that can be used for this,
and they have different purposes.  The \texttt{source\_directory}
variable is intended for reading source files, and
the \texttt{result\_directory} is intended for writing output.  See
the following subsections for details.


\subsection{The SOURCE\_DIRECTORY}
\label{sec:SOURCE_DIR}

The \texttt{SOURCE\_DIRECTORY} variable is used by
the \texttt{csvimport} method, but could be used by any method reading
input files, like in this example
\begin{python}
import os
options = dict(filename=Optionstring)

def synthesis(SOURCE_DIRECTORY):
    fname = os.path.join(SOURCE_DIRECTORY, options.filename)
\end{python}
here, the \texttt{fname} is a concatenation of
the \texttt{SOURCE\_DIRECTORY} specified in the Accelerator's
configuration file (see section ~\ref{sec:symlinking}) and the input
option \texttt{filename}.


\subsection{The RESULT\_DIRECTORY}
\label{sec:RESULT_DIR}

It is possible to define a shared directory
named \texttt{result\_directory} in the Accelerator's configuration
file.  In a method, this variable may be accessed like in this example
\begin{python}
def synthesis(RESULT_DIRECTORY):
    print(RESULT_DIRECTORY)
\end{python}
Methods could use this for storing for example plots and reports for a
project in one easy accessible common location.  Note however, that
tracking these files is not possible, there is no information linking
back from the result directory to a specific job.  This may be
overcome using for example soft file links, however, see section~\ref{sec:symlinking}.







\subsection{Understanding Workdirs}
When the \texttt{Daemon} is starting, it will read
all \texttt{workdir}-definitions in the configuration file.  It will
check that all workdirs specified by \texttt{target\_workdir}
and \texttt{source\_workdirs} are defined.  All other defined workdirs
are ignored.  The daemon will also check that all workdirs have the
same number of slices as specified in the configuration file, and that
all workdirs to be used together have the same number of slices.

The \texttt{target\_workdir} is the default location where new jobs
will be stored.  However, a build script may write jobs to any of the
\texttt{source\_workdirs} as well.  Furthermore, the \texttt{target\_workdir}
may always be read from, and may therefore be omitted from
the \texttt{source\_workdirs} list.

\subsection{How to Create New Workdirs}
If a workdir defined in the configuration file does not exist on disk
at the stated location, the Daemon will exit and print an error
stating that a directory is missing.  The first time the Daemon
encounters a new directory it will initialise it in accordance with
the configuration file.  This is true both for source and target
workspaces.  So, new workdirs are created by adding them to the
configuration file \textsl{and} creating the corresponding
directories.  The Accelerator will then initiate these directories on
the next startup.













There are three main components in the Accelerator framework, the
\texttt{daemon}, the \texttt{runner}, and \texttt{urd}.  How to
configure and run these components is the topic of this chapter.


\section{Daemon}

\subsection{Invocation}

\begin{verbatim}
daemon.py [-h] [--debug] [--config CONFIG_FILE] [--port PORT | --socket SOCKET]
\end{verbatim}

Optional arguments
\begin{snugshade}
\begin{tabular}{p{4cm}p{9cm}}
  \texttt{-h}\hspace{3cm}\texttt{---help} & show help message and
  exit.\\[4ex]

  \texttt{---debug} & Start in debug mode.  See section~\ref{MORE_INFO_ABOUT_DEBUG_FLAG}\\[2ex]
  
  \texttt{---config CONFIG\_FILE} & configuration file, default
  \texttt{../conf/framework.conf}\\[4ex]

  \texttt{---port PORT} & listen on TCP port (default \pyNone)\\[4ex]

  \texttt{---socket SOCKET} & listen on unix socket, default
  \texttt{socket.dir/default}\\[4ex]
\end{tabular}
\end{snugshade}
The Accelerator and Runner will connect using a unix socket by
default.  There is no need to configure anything.  Setting a port will
make communication happen over that port instead.



\subsection{Configuration File}
\label{sec:configfile}

The Accelerator is shipped with a configuration file template with
comments to each line.  It is a good idea to copy and modify this when
a new configuration file is needed.

Below is an example configuration file that defines two workdirs,
called \texttt{import} and
\texttt{processing}.  The workdirs are specified relative to the user's
home directory.  The workdir \texttt{processing} is the default workdir
for writing, but a build script could explicitly request to write to
the \texttt{import} workdir as well.

Methods available for use are the \texttt{standard\_methods} bundled
with the Accelerator, and methods defined in the
directory \texttt{dev} (if they are defined in \texttt{dev/methods.conf}).
\begin{leftbar}
\begin{shell}
workdir=import:${HOME}/accelerator/workdirs/import:16
workdir=processing:${HOME}/accelerator/workdirs/processing:16

target_workdir=processing

source_workdirs=import,processing

method_directories=dev,standard_methods

result_directory=${HOME}/accelerator/results

source_directory=/some/other/path

logfilename=${HOME}/accelerator/daemon.log

py2=/usr/bin/python2.7
py3=/usr/bin/python3.5
\end{shell}
\end{leftbar}
\noindent and here are explanations to all keywords
\starttabletwo

\RPtwo \texttt{workdir} & A \textsl{workdir}, defined as
\texttt{name:path:slices}.  At least one workdir needs to be defined.
All workdirs used together must have the same number of slices.  Shell
variables are available too, such as \texttt{\$\{HOME\}}, please see
text.\\[1ex]

\RPtwo \texttt{target\_workdir} & Default \textsl{workdir}
that new jobs get written to.  There can only be one target workdir.
Please see \texttt{source\_workdirs} below for more
information.\\[1ex]

\RPtwo \texttt{source\_workdirs} & A comma separated list of workdirs
available for reading.  Workdirs specified by \texttt{workdir=...}
but not listed as \texttt{target\_workdir}
or \texttt{source\_workdirs} will be ignored.  Note:
\begin{itemize}
  \item[1.] The \texttt{target\_workdir} is automatically included in
    the \texttt{source\_workdirs}, and does not need to be
    explicitly.
  \item[2.] The \texttt{target\_workdir} is the default
    workdir for writing new jobs, \textsl{but} a build script may write
    to \textsl{any} of the specified \texttt{source\_workdirs}.
\end{itemize}\\[1ex]

\RPtwo \texttt{method\_directories} & A comma separated list of
directories containing methods.  These will be the only directories
where the Accelerator can ``see'' methods.  \texttt{standard\_methods}
is bundled with the Accelerator and is commonly used.\\[1ex]

\RPtwo \texttt{result\_directory} & A common path that is available to all
jobs.  It has been used sparsely by the Accelerator team since it
voids the possibility to see where a file comes from.  Nevertheless,
in some projects it is valuable to have a common place where methods
store results, see section~\ref{}.  A way to keep traceability is to
store the file in the job directory as usual, and then create a soft
link to it in \texttt{result\_directory}.\\[1ex]

\RPtwo \texttt{source\_directory} & Default root path for
\texttt{csvimport}.  This is to avoid rebuilds of imports if source
files are moved to another directory.  (This typically happens when
setting up a similar system on another physical machine.)  See
section~\ref{} on how to get access to \texttt{source\_directory} from
any method.\\[1ex]

\RPtwo \texttt{urd} & If present, an URL to the Urd server.\\[1ex]

\RPtwo \texttt{logfilename} & Location of the Accelerator's log.\\[1ex]

\RPtwo \texttt{py2} and \texttt{py3} & path to Python executables.
Current versions of the methods in the \texttt{standard\_methods}
directory require Python2.  In the future, the Accelerator will
require Python3, so it is safest to have both here.

\stoptabletwo

It is possible to assign values in the configuration file using shell
environment variables.  In the example above, workdirs are specified
relative to \texttt{\$\{HOME\}}, for example.  In general, the
assignment is \texttt{\$\{VAR=DEFAULT\}}.



\clearpage
\subsection{Understanding Workdirs}
When the \texttt{Daemon} is starting, it will read
all \texttt{workdir}-definitions in the configuration file.  It will
check that all workdirs specified by \texttt{target\_workdir}
and \texttt{source\_workdirs} are defined.  All other defined workdirs
are ignored.  The daemon will also check that all workdirs have the
same number of slices as specified in the configuration file, and that
all workdirs to be used together have the same number of slices.

The \texttt{target\_workdir} is the default location where new jobs
will be stored.  However, a build script may write jobs to any of the
\texttt{source\_workdirs} as well.  Furthermore, the \texttt{target\_workdir}
may always be read from, and may therefore be omitted from
the \texttt{source\_workdirs} list.

\subsection{How to Create New Workdirs}
If a workdir defined in the configuration file does not exist on disk
at the stated location, the Daemon will exit and print an error
stating that a directory is missing.  The first time the Daemon
encounters a new directory it will initialise it in accordance with
the configuration file.  This is true both for source and target
workspaces.  So, new workdirs are created by adding them to the
configuration file \textsl{and} creating the corresponding
directories.  The Accelerator will then initiate these directories on
the next startup.







\clearpage
\section{Runner}

\subsection{Invocation}
The \texttt{runner} is used to execute build scripts.  it is invoked
like this
\begin{shell}
automatarunner.py [options] [script]
\end{shell}
assuming the current work directory is the \texttt{Accelerator}
directory.  The \texttt{script} is either a filename, or the suffix to
a filename starting with \texttt{automata\_}.


When the \texttt{runner} starts, it will first instruct the
Accelerator to scan all method directories to see if there are any new
or changed methods.  Thereafter, the Accelerator will proceed and scan
all source workdirs to see if any new jobs have been created (by
another Accelerator daemon).  Thereafter, it will execute the build
script.

\begin{snugshade}
\begin{tabular}{p{4cm}p{9cm}}
  \texttt{-h}\hspace{3cm}\texttt{---help} & show help message and
  exit.\\[4ex]

  \texttt{-p PORT }\hspace{3cm}\texttt{---port=PORT} & Accelerator
  listening port\\[4ex]

  \texttt{-H HOSTNAME}\hspace{3cm}\texttt{---hostname=HOSTNAME} &
  framework hostname\\[4ex]
  
  \texttt{-S SOCKET}\hspace{3cm}\texttt{---socket=SOCKET} &
  Accelerator unix socket (default
  \texttt{./socket.dir/default})\\[4ex]

  \texttt{-s SCRIPT}\hspace{1cm}\texttt{---script=SCRIPT} & build
  script to run. \texttt{package/automata\_<SCRIPT>.py}.  Defaults to
  ``\texttt{automata}''.  Can be bare arg too.\\[2ex]

  \texttt{-A}\hspace{3cm}\texttt{---abort} & abort (fail) current
  job(s).\\[4ex]

  \texttt{-P PACKAGE}\hspace{3cm}\texttt{---package=PACKAGE} & Run
  build script from this method directory.  Useful if the same script
  name exists in several method directories, for example for testing
  purposes.\\[2ex]

  \texttt{-f FLAGS}\hspace{3cm}\texttt{---flags=FLAGS} & Comma
  separated list of flags, exposed as the set \texttt{urd.flags} in
  build script.\\[2ex]
  
  \texttt{-q}\hspace{3cm}\texttt{---quick} & skip method updates and
  workdirs checking for new jobs.\\[4ex]

  \texttt{-w}\hspace{3cm}\texttt{---just\_wait} & just wait for running
  job, do not run a build script.\\[4ex]

  \texttt{---verbose=VERBOSE} & verbosity level, one of \texttt{no},
  \texttt{status}. \texttt{dots}, or \texttt{log}.\\[2ex]

  \texttt{---quiet} & same as \texttt{---verbose=no}\\[2ex]

  \texttt{---horizon=HORIZON} & Time horizon - dates after this are
  not visible in \texttt{urd.latest}.\\[4ex]
\end{tabular}
\end{snugshade}
To run a build script \texttt{automata\_myscript}, do
\begin{python}
./automatarunner myscript
\end{python}
This works as long as the name of the build script is unique, that is,
it exists in only one method directory.  If not, the method directory
can be specified using the \texttt{-P} option.

A build script named \texttt{automata.py} in a method
directory \texttt{dev} can be launched by
\begin{python}
./automatarunner -P dev
\end{python}



\subsection{Authorization to Urd}
Authorisation to Urd could be set in the \texttt{URD\_AUTH}
environment variable.  A common way to invoke the runner with Urd
authorisation is like this
\begin{shell}
% URD_AUTH=user:passwd ./runner [script]
\end{shell}
Note that the purpose of the authentication is
actually \textsl{identification}.  It is used to get write access to
certain Urd lists.  Nothing more.






\clearpage

\section{Urd}

Urd is a log-file-based transaction-log database keeping record of
jobs built by the Accelerator.  Any user can read the information
stored in Urd, but writing requires authentication.


\subsection{Setting up Urd}


\subsubsection{The Urd Files}

Urd is included in the \texttt{accelerator} repository, in the
subdirectory \texttt{accelerator/urd}.



\subsubsection{Dependencies}
Urd requires the \texttt{bottle} library to run.  It is bundled with
Debian-like systems, and can be installed by
\begin{shell}
sudo apt-get install python-bottle
\end{shell}
It can also be downloaded from the project's home page
\begin{verbatim}
https://bottlepy.org/docs/dev/
\end{verbatim}
as a single python file, \texttt{bottle.py}.  This file should be put
in the \texttt{accelerator/urd} directory.



\subsubsection{Creating a Database}
A new database is created by making a new directory and adding
a \texttt{passwd} file to it.  Urd takes care of the rest.  In
practice,
\begin{shell}
mkdir database_root
vi database_root/passwd
\end{shell}
where \texttt{vi} is just an editor picked by random.


\subsubsection{Starting Urd}
Urd is running as a daemon.  It is started like this (make sure
to \texttt{cd} into the \texttt{accelerator/urd}-directory.
\begin{shell}
./urd.py --path=<database_root> --port=<port>
\end{shell}
Where \texttt{<database\_root>} is a path to an Urd database,
and \texttt{<port>} is a port number, for example \texttt{8888}.

\subsection{The Urd Database}
The Urd database has the following structure
\begin{verbatim}
database_root/
    passwd
    database/
        user1/
            list1
            list2
        user2/
            list3
\end{verbatim}

\subsubsection{The \texttt{passwd} file}
The \texttt{passwd} file stores write access authentication.  The file
format is straightforward, each line is a user--password pair as follows
\begin{verbatim}
user:password
\end{verbatim}
For example, if the file contains the following line
\begin{verbatim}
ab:secret
\end{verbatim}
A build script issued like this
\begin{shell}
URD_AUTH=ab:secret ./automatarunner test
\end{shell}
will have write access to all lists belonging to the user \texttt{ab},
such as for example the \texttt{ab/test} and \texttt{ab/import} lists.
But it can not write to lists belonging to other users, such
as \texttt{cd/import}.  It can read all lists, though.


\subsection{Invocation}
\begin{shell}
urd.py [-h] [--port PORT] [--path PATH]
\end{shell}

\begin{snugshade}
\begin{tabular}{p{4cm}p{9cm}}
  \texttt{-h}\hspace{3cm}\texttt{---help} & show help message and
  exit.\\[4ex]

  \texttt{---port PORT} & listen on TCP port\\[4ex]

  \texttt{---path PATH} & path to database\\[4ex]
\end{tabular}
\end{snugshade}



\clearpage

\section{Workdirs}
Workdirs is where jobs are stored.  The Accelerator must have one
target workdir, and may optionally have several source workdirs.
Target and source workdirs are specified in the daemon configuration
file.

By default, only the target workdir is written to, while the source
workdirs are for reading only.  It is possible to override this,
however, by setting the \texttt{workdir}-option in
the \texttt{urd.build()} call, see section~\ref{}.

Any directory empty directory can be a workdir, and by adding it as
either source or target workdir in the configuration file, it will be
initiated at daemon startup.  The initiation process creates a file
named \texttt{<workdir>-slices.conf}, that will contain the number of
slices that is used for the workdir.

Jobdirs are stored in the workdir by the daemon, and jobdirs will
inherit the workdir name and add a suffix that is an incremental job
counter.  Here is an example of a workdir named \texttt{test}, that
contains three jobdirs.
\begin{shell}
test/
    test-slices.conf
    test-0/
    test-1/
    test-2/
    test-LATEST -> test-2
\end{shell}
The link \texttt{<workdir>-LATEST} is always pointing to the last
jobdir created.  This is useful for example when iteratively testing a
method.  Each new test will have a new jobid, but this link will
always point to the most recent one.


\subsection{Creating a Workdir}
To create a new workdir, create the directory and add it in the
configuration file either as source or target workdir.  Stop and
restart the \texttt{daemon}.  Upon startup, any uninitialised source
or target workdir in the configuration file will be initialised.




\clearpage

\section{Progress Indication}

During job building, it is possible to press \texttt{C-t},
i.e.\ \texttt{Ctrl} + \texttt{t} simultaneously, to get status
information.  The status will cover the processing state, if it is
in \prepare, \analysis, or \synthesis.  If in \analysis, it will list
all analysis processes that are active at the moment.  If iterating
over a dataset, there will be information about that, including which
dataset in a chain that is currently iterated by which \analysis
process.

Note that \texttt{C-t} could be pressed either in the \texttt{daemon}
or \texttt{runner} shells.



\clearpage

\section{Typical Installation}
Traditionally, the Accelerator is installed as a \texttt{git
submodule} to the current project it is used in.  This makes it
possible to update the Accelerator and project code independently,
while linking a specific version of the Accelerator to the project.
Thus, the project will always use a specific Accelerator commit,
making the project independent of changes to the Accelerator.

Here is a typical setup
\begin{shell}
project/
    accelerator/
    dev/
    conf/
\end{shell}
Methods are stored in the \texttt{dev} directory, and Accelerator
configuration files in \texttt{conf}.  These files are version
controlled using \texttt{git}.  The \texttt{accelerator} directory is
a \texttt{submodule}, which means that the project repository is
storing the repository location \textsl{and} the commit of the
Accelerator.


\clearpage

\section{Working with Relative Paths}

In some situations, like importing data from files, it is convenient
to store the absolute path of the files as a configuration parameter
and then work only with relative paths in the source code.  This has
two advantages.
\begin{itemize}
\item[] First, it makes it possible to move source files around without
forcing a re-build of the import jobs, and
\item[] second, absolute paths will not be stored in the source code.
\end{itemize}
In order to make use of relative paths, store the ``system dependent''
left part of the path in the Accelerator's configuration file.  There
are two variables in the configuration file that can be used for this,
and they have different purposes.  The \texttt{source\_directory}
variable is intended for reading source files, and
the \texttt{result\_directory} is intended for writing output.  See
the following subsections for details.


\subsection{The SOURCE\_DIRECTORY}
The \texttt{SOURCE\_DIRECTORY} variable is used by
the \texttt{csvimport} method, but could be used by any method reading
input files, like in this example
\begin{python}
import os
options = dict(filename=Optionstring)

def synthesis(SOURCE_DIRECTORY):
    fname = os.path.join(SOURCE_DIRECTORY, options.filename)
\end{python}
here, the \texttt{fname} is a concatenation of
the \texttt{SOURCE\_DIRECTORY} specified in the Accelerator's
configuration file (see section ~\ref{xx}) and the input
option \texttt{filename}.


\subsection{The RESULT\_DIRECTORY}
It is possible to define a shared directory
named \texttt{result\_directory} in the Accelerator's configuration
file.  In a method, this variable may be accessed like in this example
\begin{python}
def synthesis(RESULT_DIRECTORY):
    print(RESULT_DIRECTORY)
\end{python}
Methods could use this for storing for example plots and reports for a
project in one easy accessible common location.  Note however, that
tracking these files is not possible, there is no information linking
back from the result directory to a specific job.  This may be
overcome using for example soft file links, however, see section~\ref{}.


\clearpage
\section{Other Useful Functions}
The \texttt{extras} module contains a set of useful functions


\subsection{Find the Full Path of a File in Another Job}
Accessing a file stored in another job from within a method or build
script is simple, and the functionality is implemented
in \texttt{resolve\_jobid\_filename()}.  The function takes two
arguments, a \textsl{jobid} and a \textsl{filename}.  See the example
below
\begin{python}
from jobid import resolve_jobid_filename

jobids = ('oldjob',)

def synthesis():
    filename = resolve_jobid_filename(jobids.oldjob, 'nameoffile')
\end{python}
Note that this function works in a build script as well.


\subsection{Symlinking}
Creating a symlink, for example from the \texttt{result\_directory} to
current workdir, may be implemented in a very simple and safe way like
this
\begin{python}
from extras import symlink

def synthesis(RESULT_DIRECTORY):
    ...
    with open(filename, 'wb') as fh:
         fh.write(...)
    symlink(filename, RESULT_DIRECTORY)
\end{python}
The \texttt{extras.symlink} function will write a soft link
to \texttt{filename} in \texttt{RESULT\_DIRECTORY}, overwriting it if
it already exists.

\subsection{job\_params}

\subsection{job\_post}

\subsection{json\_encode}

\subsection{json\_decode}

\subsection{json\_save}

\subsection{json\_load}

\subsection{blob\_load}

\subsection{blob\_save}


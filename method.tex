\section{Methods}

Methods are source files executed by the framework.  The nomenclature
is that methods turn into jobs when they are assigned input arguments
and get executed by the framework.  A method may be dispatched by urd,
or by another method as a subjob.



\section{Packages and Source code}

Methods are stored in directories, called packages, in the main
framework directory.  A package needs to be present in the main
configuration file, and the package directory has to contain the file
\texttt{\_\_init\_\_.py} for Python to see it.

There are two limitations, that apply to methods, designed to avoid
accidental execution of the wrong source code.  For a method file to
be accepted by the framework, the filename has to start with the
prefix \texttt{``a\_''}.  Furthermore, the method name, without this
prefix must be present on a separate line in the \texttt{methods.conf}
file for the package.



\section{Recall and Method Hashing}

The framework is applying a hash function to the method source code to
determine if a job may be recalled or re-executed.  Changing the
method source code in an unique way causes a new job to be built from
the method code.

A method may use code located in other files, and in that case it is
possible to ensure that jobs are dispatched if any of those files
change.  This is specified in the method using the
\texttt{depend\_extra} list, as for example:
\\
\begin{python}
import generic_params
depend_extra = (generic_params, 'mystuff.data',)
\end{python}
\\
You can specify a module object or a filename relative to the module
source.

A different scenario is when the method source code needs to be
modified, but the change does not alter past behavior, i.e.\ remake of
jobs should be actively avoided.  There is an
\texttt{equivalent\_hashes} dict for that, as shown
\\
\begin{python}
  equivalent_hashes = {'verifier': ('0c573685f713ac6500a6eda7df1a7b3f',)}
\end{python}

The verifier string is a hash that depends on everything in the method
except the equivalent\_hashes block. It is there to avoid the scenario
where you forget the method has equivalent\_hashes and make changes. When
the verifier is wrong (as it will be after editing the method) you will be
informed what the correct verifier would be, so you can use that or discard
the equivalent\_hashes block, as appropriate. The tuple on the right can
contain any number of old hashes.



\section{Method Inputs}

When a method is dispatched as a job, it will be provided with input
from the dispatcher.  There are three kinds of input to a method:
\jobids, \datasets, and \options.  These are specified early in the
method source code, such as for example
\\
\begin{python}
jobids = ('accumulated_costs',)
datasets = ('transaction_log',)
options = dict(length=4)
\end{python}
\\
The \texttt{jobids} argument is used to input pointers to other
finished jobs, \datasets is used to input other datasets, and \options
is used to input any other type of parameters specifying running
behavior of the method.  Note that \jobids and \datasets are tuples
(and a single entry has to be followed by a comma), while \options is
a dictionary.  Each will be described in more detail next



\subsection{Input Jobids}
The \jobids argument is a tuple of jobids linking this job to other
jobs.  Inside the running method, a jobid from the \jobids tuple is
simply a string that can be passed to various helper functions in
order to use results from the corresponding jobs.



\subsection{Input Datasets}
The \datasets argument is the way to communicate datasets from
automata to job.  In the running method, the \datasets variable is a
tuple of dataset objects ready to use.  The dataset class is described
in a dedicated chapter.




\subsection{Input Options}

The \options argument is of type \texttt{dict} and used to pass
various information from the dispatcher (typically Urd or a method) to
a method.  Information could be integers, strings, enumerations, sets,
lists, and dicts in a recursive fashion.  Options may have a default
value.

Options are defined in a method like this
\\
\begin{python}
  options = dict( ... )  # or
  options = { ... }
\end{python}

Options are easiest described by examples, and such will be presented
in the following sections.  The remaining of this section is dedicated
to describe the formal rules for option typing and assignment.

 \begin{itemize}
 \item an input value is required to be of the correct type.

 \item An input may be left unassigned, unless
   \begin{itemize}
   \item typing is RequiredOptions(), or
   \item OptionEnum without default
   \end{itemize}
   
 \item Typing may be specified using the class name (i.e.\ int), or as
   a value that will construct into such a class object (i.e.\ the
   number 3).

 \item If typing is specified as a value, this is the default value if
   left unspecified.

 \item If typing is specified as a class name, default is None.

 \item Values are accepted if they are valid input to the type's
   constructor, i.e.\ 3 and '3' are valid input for an integer.

 \item None is a valid input unless
   \begin{itemize}
   \item RequiredOptions() and not none\_ok set
   \item OptionEnum() and not none\_ok set
   \end{itemize}

 \item All containers can be specified as empty (?)

 \item Complex types (like dicts, dicts of lists of dicts, ...) never
   enforce specific keys, only types. (\{'a': 'b'\} is a valid value
   for \{'foo': 'bar'\}) (?)
   
 \item containers with a type in the values default to empty
   containers (otherwise the specified values are the default contents)

\end{itemize}
%%%
%%%

Typing and default values are presented in the following sections.
Default values are assigned if there is no input.  Note that
definition of type is that the constructor must accept the value
provided, for example the string \texttt{'3'} is a valid input for the
\texttt{int} constructor.


\subsubsection{Unspecifieds}
An option with no typing may be specified by assigning \texttt{None}.
\\
\begin{python}
  options = dict(length=None)
  # accepts anything, default is None
\end{python}
\\
Here, \texttt{length} could be set to anything.



\subsubsection*{Scalars}
Scalars are either explicitly typed, as
\\
\begin{python}
  options = dict(length=int)
  # Requires an intable value or None
\end{python}
\\
or implicitly with default value like

\begin{python}
  options = dict(length=3)
  # Requires an intable value, default is 3 if left unassigned
\end{python}
\\
In these examples, intable means that the value provided should be
valid input to the \texttt{int} constructor, for example the number~3
or the string \texttt{'3'} both yield the integer number 3.



\subsubsection*{Strings}
A (possibly empty) string with default value \texttt{None} is typed as
\\
\begin{pythonBEG}
  # requires string or None, defaults to None
  options = dict(name=str)
\end{pythonBEG}
\\
A default value may be specified as follows
\\
\begin{pythonMID}
  # requires string or None, provides default value
  options = dict(name='foo')
\end{pythonMID}
\\
And a string required to be specified and none-empty as
\\
\begin{pythonMID}
  # requires non-empty string
  options = dict(name=OptionString)
\end{pythonMID}
\\
In some situations, an example string is convenient
\\
\begin{pythonEND}
  # Requires string, provides example (NOT default value)
  options = dict(name=OptionString('bar')
\end{pythonEND}
\\
Note that 'bar' is not default, it just gives the programmer a way to
express what is expected.



\subsubsection*{Enums}
Enumerations are convenient in a number of situations.  They are typed
as follows
\\
\begin{pythonBEG}
  # Requires one of the strings 'a', 'b' or 'c'
  options = dict(foo=OptionEnum('a b c'))
\end{pythonBEG}
\\
A default value may be specified like this
\\
\begin{pythonMID}
   # Requires one of the strings 'a', 'b' or 'c', defaults to 'b'
  options = dict(foo=OptionEnum('a b c').b
\end{pythonMID}
\\
or, like this, accepting \texttt{None}
\\
\begin{pythonMID}
  # Requires one of the strings 'a', 'b', or 'c'; or None
  options = dict(foo=OptionEnum('a b c', none_ok=True))
\end{pythonMID}
\\
The \texttt{none\_ok} flag may be combined with a default value too.
\\
Furthermore, the asterisk-wildcard may be used too
\\
\begin{pythonEND}
  # Requires one of the strings 'a', 'b', or any string starting with 'c'
  options = dict(foo=OptionEnum('a b c*'))
\end{pythonEND}



\subsubsection*{Lists and Sets}
Lists and sets are specified like this
\\
\begin{pythonBEG}
  # Requires list of intable, defaults to empty list
  options=dict(foo=[int])
\end{pythonBEG}
\\
and
\\
\begin{pythonEND}
  # Requires set of intable, defaults to empty set
  options=dict(foo={int})
\end{pythonEND}



\subsubsection*{More complex stuff}
It is possible to have more complex types, such as dictionaries of
dictionaries and so on, for example
\\
\begin{pythonBEG}
  # Requires dict of string to string
  options = dict(foo={str: str})
\end{pythonBEG}
\\
or another example
\\
\begin{pythonEND}
  # Requires dict of string to dict of string to int
  options = dict(foo={str: {str: int}})
\end{pythonEND}
\\
Containers with a type in the values default to empty containers.
Otherwise, the specified values are the default contents.



\subsubsection*{Date and Time}
The following date and time related types are supported:
\texttt{datetime}, \texttt{date}, \texttt{time}, and
\texttt{timedelta}.  A typical usecase is as follows
\\
\begin{pythonBEG}
  # a datetime object if input, or None
  options = dict(ts=datetime)
\end{pythonBEG}
\\
and with a default assignment
\\
\begin{pythonEND}
  #  a datetime object if input, defaults to a datetime(2014, 1, 1) object
  options = dict(ts=datetime(2014, 1, 1))
\end{pythonEND}



\subsubsection*{JobWithFile}
Any file residing in a jobdir may be input to a method like this
\\
\begin{pythonBEG}
  options = dict(usefile=JobWithFile(jid, 'user.txt')
\end{pythonBEG}
\\
There are two additional arguments, \texttt{sliced} and
\texttt{extras}.  The \texttt{extras} argument is used to pass any
information that is helpful in using the specified file, and
\texttt{sliced} tells that the file is stored in parallel slices.
\\
\begin{pythonMID}
options = dict(usefile=JobWithFile(jid, 'user.txt', sliced=True, extras={'uid': 37}))
\end{pythonMID}
\\
In the method, the \texttt{JobWithFile} object has these members
\\
\begin{pythonEND}
  usefile.jobid
  usefile.filename
  usefile.sliced
  usefile.extras
\end{pythonEND}
\\
Where the full filename of the file is available through
\\
\begin{python}
from extras import full_filename
print full_filename(filename, '')
\end{python}
\\
The mandatory string (which is empty in this case, is a filename
extension.  \textbf{Will be changed!})





\newpage
\section{Code Flow:  \prepare, \analysis, and \synthesis}

There are three pre-defined functions in a method, \prepare,
\analysis, and \synthesis, and they are always run in that order.
\prepare and \synthesis are single threaded, while \analysis provides
parallel execution.

The following combinations are valid and are of practical use
\begin{itemize}
\item \synthesis-only, used for a single threaded program
\item \analysis-only, used for completely parallel tasks
\item \prepare + \analysis, setup and run a parallel job
\item \analysis + \synthesis, run a parallel job and combine outputs
\item \prepare + \analysis + \synthesis, setup, run, and combine a
  parallel task.
\end{itemize}
All the three functions take \options, \jobids, and \datasets as
optional arguments.  The \analysis function takes a required argument
\texttt{sliceno}, which is an integer between zero and the total
number of slices minus one.  This is the unique identity indicator for
the \analysis process.

Return values may be passed from one function to another.  What is
returned from prepare is called \prepareres, and may be used as input
argument to \analysis and \synthesis.  The return values from
\analysis is available as \analysisres in \synthesis.  The return
value from \synthesis is stored permanently in the jobdir.  A complete
example may look like
\\
\begin{python}
options = dict(length=4)
datasets = ('transaction_log')

def prepare(options):
  return options.length * 2

def analysis(sliceno, prepare_res):
  return set(
    u for u in datasets.transaction_log.iterate(sliceno, 'user')
  )

def synthesis(analysis_res, prepare_res):
   return analyses_res.merge_auto()
\end{python}


\subsection{The \params Variable }
The \params variable contain all input and initialization parameters
for a job, such as the caption
\\
\begin{python}
def synthesis(params):
  print params.caption
# urd_dispatched_method1
\end{python}
\\
The \params variable contains lots of information that is typically
not required in a regular method.  For a method developer, the most
important members are
\\
\begin{python}
params.package     # which package the method source code is stored in
params.slices      # number of slices for the workdirs in use
params.caption     # may be specified when building a job
params.seed        # seed to initialize a random number generator
params.starttime   # execution start in epoch time
\end{python}
\\
but params does also contain all options, jobids, and datasets inputs.



\subsection{Accessing Another Job's \params using \jobparams}

The \params data structure contains all input and initialization data
for a job.  To access another job's \params variable, just feed the
job's jobid into the \jobparams function.
\\
\begin{python}
from extras import job_params

jobids = ('anotherjob',)

def synthesis():
  print jobids.anotherjob
  # will print something like 'jid-0_0'
  print job_params(jobids.anotherjob).options
  # will print something like {length: 3}
\end{python}




\newpage
\section{More on Intermediate and Result Files}

\subsection{Sharing Data Inside a Job}
Data is easily shared between \prepare, \analysis, and \synthesis as
follows.
\begin{itemize}
\item what is returned in \prepare is available as \prepareres in \analysis and \synthesis
\item what is returned in \analysis is available as \analysisres in \synthesis.  \analysisres is an iterator.
\item what is returned in \synthesis is a persistent file in the job catalog referenced by \texttt{result}.
\end{itemize}

\subsubsection*{The blob module}
The simplest way to share intra job data is using the blob module.
\\
\begin{python}
import blob
def synthesis()
  blob.load('filename')
\end{python}
\\
saving data is as follows
\\
\begin{python}
  blob.save(data, filename, sliceno=None, temp=None)
\end{python}
\\
\sliceno and \texttt{temp} are optional.  If \sliceno is set, data is
stored in a sliced file.  This is typically used in \analysis, where
each thread will save its own file.  The argument \texttt{temp} is
used for file persistence.  By default, files are stored permanently
when a job terminates successfully.  Setting \texttt{temp} to
\texttt{True} removes them upon completion of the job.  Temporary
files are useful when communicating data between the functions in the
method (and not using the res-files) or in debugging.


\subsection{debug help}
There is also a more advanced debug functionality relating to temp.
\\
\begin{python}
from extras import Temp
def analysis(sliceno):
  ...
  blob.save(data, filename, sliceno=sliceno, temp=Temp.DEBUG)
  # or
  blob.save(data, filename, sliceno=sliceno, temp=Temp.DEBUGTEMP)
\end{python}
\\
where the first only stores when \texttt{--debug} is specified, and
the other always stores but removes unless \texttt{--debug} is set.


\newpage
\section{Subjobs}

Jobs may launch subjobs.  If the jobs are already built, they will be
immediately linked in.  The syntax is as follows, assuming we build
the jobs in \\prepare:
\\
\begin{python}
import subjobs

def prepare():
  subjobs.build('count_items', options=dict(length=3))
\end{python}
\\
The \texttt{subjobs.build} uses the same syntax as \texttt{urd.build}
described elsewhere, so \options, \datasets, \jobids, and
\texttt{caption} are available.  Similarly, subjob jobid is returned.

If there are datasets built in a subjob, these will not be explicitly
available to Urd.  Instead, the dataset definition may be copied to
the launching method like this
\\
\begin{python}
from Dataset import dataset

def synthesis():
  jid = subjobs.build('create_dataset')
  Dataset(jid).link_to_here(name='thename')
\end{python}
\\
the \texttt{name} argument is optional, the name \texttt{default} is
used if left empty, corresponding to the default dataset.

Currently there is no dependency checking on subjobs, so if a subjob
method is changed, the calling method will not be updated.  The
current remedy is to use \texttt{depend\_extra} in the callin method,
like this
\\
\begin{python}
import subjobs

depend_extra = ('a_childjob.py',)

def prepare():
  subjobs.build('childjob')
\end{python}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                          %
% Copyright (c) 2018 eBay Inc.                                             %
% Modifications copyright (c) 2019-2021 Anders Berkeman                    %
%                                                                          %
% Licensed under the Apache License, Version 2.0 (the "License");          %
% you may not use this file except in compliance with the License.         %
% You may obtain a copy of the License at                                  %
%                                                                          %
%  http://www.apache.org/licenses/LICENSE-2.0                              %
%                                                                          %
% Unless required by applicable law or agreed to in writing, software      %
% distributed under the License is distributed on an "AS IS" BASIS,        %
% WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. %
% See the License for the specific language governing permissions and      %
% limitations under the License.                                           %
%                                                                          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

ExAx, or the Accelerator, is a tool for fast reproducible data processing,
capable of working at high speed with terabytes of data with billions
of rows on a single computer.  The speed in combination with its
unique capabilites to ensure reproducibility makes the Accelerator a
good choice for tasks where it is important to keep track of how data
and results are connected.  Typical applications include all kinds of
data analysis work as well as live production systems for tasks such
as recommender systems, and more.  The Accelerator has a small
footprint, few dependencies, and runs on laptops as well as rack
servers.

The Accelerator was first used in 2012, and has been continuously developed and
improved since.  It has been in use in projects for companies like
\textsl{Safeway}, \textsl{Starbucks}, \textsl{eBay}, \textsl{Ericsson},
and \textsl{Vodafone}, among others.  Most projects have been related to data
analysis, some to optimisation, and some projects have been
recommender systems running live for years.  The Accelerator has
been the core of these projects.  In 2016, the Accelerator was
acquired by Ebay, who contributed it to the open source community
early 2018.

The sizes of typical data sets used in these projects range from a few
hundred lines up to several tens of billions rows and many columns.
The number of items in a dataset used in a live system was well above
$10^{11}$, and this was handled with ease on a \emph{single} 32 core
computer.

More than 1600 commits have been removed to clean up the open version
of the code base, and about 1300 new commits have been created since
the Accelerator was open sourced.  The Accelerator is written in
Python, with the exception of some critical parts that are written in
the C programming language.

The authors are Anders Berkeman, Carl Drougge, and Sofia H\"orberg.
Extensive testing has been done by Stefan Weiland, and Andreas
Ottosson has been proofreading.



\section{Main Design Goals}
The Accelerator was originally developed for reproducible,
transparent, and maximally fast data processing using all available
CPU cores.  It is designed bottom up for high performance and
simplicity, and the main design goals are:
\begin{itemize}

\item[] \textsl{Parallel processing} should be made simple.  Modern computers
  come with several CPU cores.  It should be straightforward to use
  them to speed up computations.
  
\item[] Data rates should be as fast as possible, i.e.\ close to the hardware
  bounds.  It should be possible to process \textsl{large datasets} on
  inexpensive hardware, including laptops.

\item[] All processing steps should be \textsl{reproducible}.
  The Accelerator maps any generated result to its corresponding input
  data and processing source code.

\item[] Never recompute old results, always ``recycle'' old jobs, when
  possible.  \textsl{Sharing} computed results between multiple users
  should be effortless.

\item[] \textsl{Organise} and keep track of all jobs, input files,
  intermediate files, and results in order to work with projects having
  100.000s of input files and lots of programs and scripts processing
  them.
  
\end{itemize}
In addition, the Accelerator is originally designed to be used at all
levels of a project, including data analysis, algorithm development,
as well as production.  Nevertheless, it still excels as a pure data
analysis or data processing tool.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                          %
% Copyright (c) 2018 eBay Inc.                                             %
%                                                                          %
% Licensed under the Apache License, Version 2.0 (the "License");          %
% you may not use this file except in compliance with the License.         %
% You may obtain a copy of the License at                                  %
%                                                                          %
%  http://www.apache.org/licenses/LICENSE-2.0                              %
%                                                                          %
% Unless required by applicable law or agreed to in writing, software      %
% distributed under the License is distributed on an "AS IS" BASIS,        %
% WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. %
% See the License for the specific language governing permissions and      %
% limitations under the License.                                           %
%                                                                          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The Accelerator is a tool for fast reproducible data processing,
capable of working at high speed with terabytes of data with billions
of rows on a single computer.  The speed in combination with its
unique capabilites to ensure reproducibility makes the Accelerator a
good choice for tasks where it is important to keep track of how data
and results are connected.  Typical applications include all kinds of
data analysis work as well as live production systems for tasks such
as recommendation systems, and more.  The Accelerator has a small
footprint, few dependencies, and runs on laptops as well as rack
servers.

The Accelerator was first used in 2012, and has been continuously developed and
improved since.  It has been in use in projects for companies like
\textsl{Safeway}, \textsl{Starbucks}, \textsl{eBay}, \textsl{Ericsson},
and \textsl{Vodafone}.  Most project have been related to data
analysis, some to optimisation, and some projects have been
recommendation systems running live for years.  The Accelerator has
been the core of these projects.  In 2016, the Accelerator was
acquired by Ebay, who contributed it to the open source community
early 2018.

Data set sizes in these projects range from a few hundred lines up to
several tens of billions rows and many columns.  The number of
items in a dataset used in a live system was well above $10^{11}$, and
this was handled with ease on a \emph{single} 32 core computer.

The authors are Anders Berkeman, Carl Drougge, and Sofia H\"orberg.
More than 1600 commits have been removed to clean up the open version
of the code base.  Extensive testing has been done by Stefan
H{\aa}konsson.  The Accelerator is written in Python, with the
exception of some critical parts that are written in the C programming
language.



\section{Main Design Goals}
The Accelerator is designed to process log-files in ``CSV''-like
formats\footnote{CSV is short for Comma Separated Values, but any
separator character can be used.  CSV files store data into rows and
columns of text.  Classical ``databases'' could be generated from, and
dumped to, CSV-files.}.  Log files bring determinism (i.e.\
reproducibility) and transparency, and most data can be represented in
this format.  The Accelerator is developed bottom up for high
performance and simplicity, and the main design goals are:
\begin{itemize}

\item[] \textsl{Parallel processing} should be made simple.  Modern computers
  come with several cores, it should be straightforward to make use of
  them.

\item[] Data rates should be as fast as possible, i.e.\ close to the hardware
bounds.  It should be possible to process \textsl{large datasets},
  even on commodity hardware.

\item[] Any processing step should be \textsl{reproducible}.
The Accelerator maps any output result to its corresponding input data and
processing source code.

\item[] Never recompute old results, always ``recycle'' old jobs, when
  possible.  Also, \textsl{sharing results} between multiple users should be
  effortless.

\item[] \textsl{Organise} and keep track of all jobs, files, and results in
  order to work with projects having 100.000s of input files and lots
  of programs and scripts processing them.
  
\end{itemize}
In addition, the Accelerator is originally designed to be used at all
levels of a project, including data analysis, algorithm development,
as well as production.  Nevertheless, it still excels as a pure data
analysis or data processing tool.
